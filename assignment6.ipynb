{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bCy5FCpE9yY",
        "outputId": "ad30d2d8-9e29-4542-d405-f05da6668425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.14.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.36.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2024.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.2)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.43)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.31)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<23 in /usr/local/lib/python3.10/dist-packages (from mlflow) (22.0.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.46b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.14.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Torch version: 2.3.0+cu121\n",
            "Cuda available: False\n",
            "Torch geometric version: 2.5.3\n",
            "Torch version: 2.3.0+cu121\n",
            "Cuda available: False\n",
            "Torch geometric version: 2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy mlflow streamlit pandas torch torch_geometric tqdm deepchem rdkit matplotlib seaborn\n",
        "import numpy as np\n",
        "from mlflow.models.signature import ModelSignature\n",
        "from mlflow.types.schema import Schema, TensorSpec\n",
        "\n",
        "\n",
        "HYPERPARAMETERS = {\n",
        "    \"batch_size\": [32, 128, 64],\n",
        "    \"learning_rate\": [0.1, 0.05, 0.01, 0.001],\n",
        "    \"weight_decay\": [0.0001, 0.00001, 0.001],\n",
        "    \"sgd_momentum\": [0.9, 0.8, 0.5],\n",
        "    \"scheduler_gamma\": [0.995, 0.9, 0.8, 0.5, 1],\n",
        "    \"pos_weight\" : [1.0],\n",
        "    \"model_embedding_size\": [8, 16, 32, 64, 128],\n",
        "    \"model_attention_heads\": [1, 2, 3, 4],\n",
        "    \"model_layers\": [3],\n",
        "    \"model_dropout_rate\": [0.2, 0.5, 0.9],\n",
        "    \"model_top_k_ratio\": [0.2, 0.5, 0.8, 0.9],\n",
        "    \"model_top_k_every_n\": [0],\n",
        "    \"model_dense_neurons\": [16, 128, 64, 256, 32]\n",
        "}\n",
        "\n",
        "BEST_PARAMETERS = {\n",
        "    \"batch_size\": [128],\n",
        "    \"learning_rate\": [0.01],\n",
        "    \"weight_decay\": [0.0001],\n",
        "    \"sgd_momentum\": [0.8],\n",
        "    \"scheduler_gamma\": [0.8],\n",
        "    \"pos_weight\": [1.3],\n",
        "    \"model_embedding_size\": [64],\n",
        "    \"model_attention_heads\": [3],\n",
        "    \"model_layers\": [4],\n",
        "    \"model_dropout_rate\": [0.2],\n",
        "    \"model_top_k_ratio\": [0.5],\n",
        "    \"model_top_k_every_n\": [1],\n",
        "    \"model_dense_neurons\": [256]\n",
        "}\n",
        "\n",
        "input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 30), name=\"x\"),\n",
        "                       TensorSpec(np.dtype(np.float32), (-1, 11), name=\"edge_attr\"),\n",
        "                       TensorSpec(np.dtype(np.int32), (2, -1), name=\"edge_index\"),\n",
        "                       TensorSpec(np.dtype(np.int32), (-1, 1), name=\"batch_index\")])\n",
        "\n",
        "output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 1))])\n",
        "\n",
        "SIGNATURE = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#utils -\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "import mlflow\n",
        "import deepchem as dc\n",
        "import requests\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "\n",
        "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "\n",
        "\n",
        "def smiles_to_mol(smiles_string):\n",
        "    \"\"\"\n",
        "    Loads a rdkit molecule object from a given smiles string.\n",
        "    If the smiles string is invalid, it returns None.\n",
        "    \"\"\"\n",
        "    return Chem.MolFromSmiles(smiles_string)\n",
        "\n",
        "def mol_file_to_mol(mol_file):\n",
        "    \"\"\"\n",
        "    Checks if the given mol file is valid.\n",
        "    \"\"\"\n",
        "    return Chem.MolFromMolFile(mol_file)\n",
        "\n",
        "def draw_molecule(mol):\n",
        "    \"\"\"\n",
        "    Draws a molecule in SVG format.\n",
        "    \"\"\"\n",
        "    return MolToImage(mol)\n",
        "\n",
        "def mol_to_tensor_graph(mol):\n",
        "    \"\"\"\n",
        "    Convert molecule to a graph representation that\n",
        "    can be fed to the model\n",
        "    \"\"\"\n",
        "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
        "    f = featurizer.featurize(Chem.MolToSmiles(mol))\n",
        "    data = f[0].to_pyg_graph()\n",
        "    data[\"batch_index\"] = torch.ones_like(data[\"x\"][:, 0])\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_model_predictions(payload):\n",
        "    \"\"\"\n",
        "    Get model predictions\n",
        "    ENDPOINT = Calls an endpoint to get the predictions\n",
        "    REGISTRY = Loads model from registry and predicts\n",
        "    MOCKED = Randomly generated prediction\n",
        "    \"\"\"\n",
        "    option=\"MOCKED\"\n",
        "\n",
        "    if option == \"ENDPOINT\":\n",
        "        # Currently not supported for multi-input models\n",
        "        DEPLOYED_ENDPOINT = \"http://127.0.0.1:5001/invocations\"\n",
        "        headers = {\"Content-Type\":\"application/json\"}\n",
        "        prediction = requests.post(url=DEPLOYED_ENDPOINT,\n",
        "                                   data={\"inputs\": {\n",
        "                                            \"x\": payload[\"x\"].numpy(),\n",
        "                                            \"edge_attr\": payload[\"edge_attr\"].numpy(),\n",
        "                                            \"edge_index\": payload[\"edge_index\"].numpy().astype(np.int32),\n",
        "                                            \"batch_index\": np.expand_dims(payload[\"batch_index\"].numpy().astype(np.int32), axis=1)\n",
        "                                        }}, headers=headers)\n",
        "        prediction = json.loads(prediction.content.decode(\"utf-8\"))\n",
        "\n",
        "    if option == \"REGISTRY\":\n",
        "        # Currently not supported for multi-input models\n",
        "        model_name = \"GraphTransformer\"\n",
        "        model_version = \"2\"\n",
        "        model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
        "\n",
        "\n",
        "        prediction = model.predict({\n",
        "            \"x\": payload[\"x\"].numpy(),\n",
        "            \"edge_attr\": payload[\"edge_attr\"].numpy(),\n",
        "            \"edge_index\": payload[\"edge_index\"].numpy().astype(np.int32),\n",
        "            \"batch_index\": np.expand_dims(payload[\"batch_index\"].numpy().astype(np.int32), axis=1)\n",
        "        })\n",
        "\n",
        "    if option == \"MOCKED\":\n",
        "        # Fake API call\n",
        "        time.sleep(2)\n",
        "        prediction = random.choice([0,1])\n",
        "\n",
        "    return prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#dashboard\n",
        "import streamlit as st\n",
        "# ----------- General things\n",
        "st.title('HIV Inhibitor Dashboard')\n",
        "valid_molecule = True\n",
        "loaded_molecule = None\n",
        "selection = None\n",
        "submit = None\n",
        "\n",
        "# ----------- Sidebar\n",
        "page = st.sidebar.selectbox('Page Navigation', [\"Predictor\", \"Model analysis\"])\n",
        "\n",
        "st.sidebar.markdown(\"\"\"---\"\"\")\n",
        "st.sidebar.write(\"Created by [DeepFindr](https://www.youtube.com/channel/UCScjF2g0_ZNy0Yv3KbsbR7Q)\")\n",
        "\n",
        "if page == \"Predictor\":\n",
        "    # ----------- Inputs\n",
        "    st.markdown(\"Select input molecule.\")\n",
        "    upload_columns = st.columns([2, 1])\n",
        "\n",
        "    # File upload\n",
        "    file_upload = upload_columns[0].expander(label=\"Upload a mol file\")\n",
        "    uploaded_file = file_upload.file_uploader(\"Choose a mol file\", type=['mol'])\n",
        "\n",
        "    # Smiles input\n",
        "    smiles_select = upload_columns[0].expander(label=\"Specify SMILES string\")\n",
        "    smiles_string = smiles_select.text_input('Enter a valid SMILES string.')\n",
        "\n",
        "    # If both are selected, give the option to swap between them\n",
        "    if uploaded_file and smiles_string:\n",
        "        selection = upload_columns[1].radio(\"Select input option\", [\"File\", \"SMILES\"])\n",
        "\n",
        "    if selection:\n",
        "        if selection == \"File\":\n",
        "            # Save it as temp file\n",
        "            temp_filename = \"temp.mol\"\n",
        "            with open(temp_filename, \"wb\") as f:\n",
        "                f.write(uploaded_file.getbuffer())\n",
        "            loaded_molecule = mol_file_to_mol(temp_filename)\n",
        "        elif selection== \"SMILES\":\n",
        "            loaded_molecule = smiles_to_mol(smiles_string)\n",
        "    else:\n",
        "        if uploaded_file:\n",
        "            # Save it as temp file\n",
        "            temp_filename = \"temp.mol\"\n",
        "            with open(temp_filename, \"wb\") as f:\n",
        "                f.write(uploaded_file.getbuffer())\n",
        "            loaded_molecule = mol_file_to_mol(temp_filename)\n",
        "        elif smiles_string:\n",
        "            loaded_molecule = smiles_to_mol(smiles_string)\n",
        "\n",
        "    # Set validity flag\n",
        "    if loaded_molecule is None:\n",
        "            valid_molecule = False\n",
        "    else:\n",
        "        valid_molecule = True\n",
        "\n",
        "    # Draw if valid\n",
        "    if not valid_molecule and (smiles_string != \"\" or uploaded_file is not None):\n",
        "        st.error(\"This molecule appears to be invalid :no_entry_sign:\")\n",
        "    if valid_molecule and loaded_molecule is not None:\n",
        "        st.info(\"This molecule appears to be valid :ballot_box_with_check:\")\n",
        "        pil_img = draw_molecule(loaded_molecule)\n",
        "        upload_columns[1].image(pil_img)\n",
        "        submit = upload_columns[1].button(\"Get predictions\")\n",
        "\n",
        "    # ----------- Submission\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    if submit:\n",
        "        with st.spinner(text=\"Fetching model prediction...\"):\n",
        "            # Convert molecule to graph features\n",
        "            graph = mol_to_tensor_graph(loaded_molecule)\n",
        "            # Call model endpoint\n",
        "            prediction = get_model_predictions(graph)\n",
        "\n",
        "        # ----------- Ouputs\n",
        "        outputs = st.columns([2, 1])\n",
        "        outputs[0].markdown(\"HIV Inhibitor Prediction: \")\n",
        "\n",
        "        if prediction == 1:\n",
        "            outputs[1].success(\"Yes\")\n",
        "        else:\n",
        "            outputs[1].error(\"No\")\n",
        "\n",
        "        prediction_details = st.expander(label=\"Model details\")\n",
        "        details = prediction_details.columns([2, 1])\n",
        "\n",
        "        # All of this is mocked\n",
        "        details[0].markdown(\"Confidence: \")\n",
        "        details[0].markdown(\"Model Version: \")\n",
        "        details[0].markdown(\"Model Name: \")\n",
        "        details[0].markdown(\"Test ROC: \")\n",
        "        details[1].markdown(\"81%\")\n",
        "        details[1].markdown(\"1.0.1\")\n",
        "        details[1].markdown(\"Graph Transformer Network\")\n",
        "        details[1].markdown(\"0.84\")\n",
        "else:\n",
        "    st.markdown(\"This page is not implemented yet :no_entry_sign:\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#dataset\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
        "\n",
        "\"\"\"\n",
        "!!!\n",
        "NOTE: This file was replaced by dataset_featurizer.py\n",
        "but is kept to illustrate how to build a custom dataset in PyG.\n",
        "!!!\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class MoleculeDataset(Dataset):\n",
        "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
        "        \"\"\"\n",
        "        root = Where the dataset should be stored. This folder is split\n",
        "        into raw_dir (downloaded dataset) and processed_dir (processed data).\n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.filename = filename\n",
        "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
        "            (The download func. is not implemented here)\n",
        "        \"\"\"\n",
        "        return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "\n",
        "        if self.test:\n",
        "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
        "        else:\n",
        "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data = pd.read_csv(self.raw_paths[0])\n",
        "        for index, mol in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "            mol_obj = Chem.MolFromSmiles(mol[\"smiles\"])\n",
        "            # Get node features\n",
        "            node_feats = self._get_node_features(mol_obj)\n",
        "            # Get edge features\n",
        "            edge_feats = self._get_edge_features(mol_obj)\n",
        "            # Get adjacency info\n",
        "            edge_index = self._get_adjacency_info(mol_obj)\n",
        "            # Get labels info\n",
        "            label = self._get_labels(mol[\"HIV_active\"])\n",
        "\n",
        "            # Create data object\n",
        "            data = Data(x=node_feats,\n",
        "                        edge_index=edge_index,\n",
        "                        edge_attr=edge_feats,\n",
        "                        y=label,\n",
        "                        smiles=mol[\"smiles\"]\n",
        "                        )\n",
        "            if self.test:\n",
        "                torch.save(data,\n",
        "                    os.path.join(self.processed_dir,\n",
        "                                 f'data_test_{index}.pt'))\n",
        "            else:\n",
        "                torch.save(data,\n",
        "                    os.path.join(self.processed_dir,\n",
        "                                 f'data_{index}.pt'))\n",
        "\n",
        "    def _get_node_features(self, mol):\n",
        "        \"\"\"\n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of Nodes, Node Feature size]\n",
        "        \"\"\"\n",
        "        all_node_feats = []\n",
        "\n",
        "        for atom in mol.GetAtoms():\n",
        "            node_feats = []\n",
        "            # Feature 1: Atomic number\n",
        "            node_feats.append(atom.GetAtomicNum())\n",
        "            # Feature 2: Atom degree\n",
        "            node_feats.append(atom.GetDegree())\n",
        "            # Feature 3: Formal charge\n",
        "            node_feats.append(atom.GetFormalCharge())\n",
        "            # Feature 4: Hybridization\n",
        "            node_feats.append(atom.GetHybridization())\n",
        "            # Feature 5: Aromaticity\n",
        "            node_feats.append(atom.GetIsAromatic())\n",
        "            # Feature 6: Total Num Hs\n",
        "            node_feats.append(atom.GetTotalNumHs())\n",
        "            # Feature 7: Radical Electrons\n",
        "            node_feats.append(atom.GetNumRadicalElectrons())\n",
        "            # Feature 8: In Ring\n",
        "            node_feats.append(atom.IsInRing())\n",
        "            # Feature 9: Chirality\n",
        "            node_feats.append(atom.GetChiralTag())\n",
        "\n",
        "            # Append node features to matrix\n",
        "            all_node_feats.append(node_feats)\n",
        "\n",
        "        all_node_feats = np.asarray(all_node_feats)\n",
        "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_edge_features(self, mol):\n",
        "        \"\"\"\n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of edges, Edge Feature size]\n",
        "        \"\"\"\n",
        "        all_edge_feats = []\n",
        "\n",
        "        for bond in mol.GetBonds():\n",
        "            edge_feats = []\n",
        "            # Feature 1: Bond type (as double)\n",
        "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
        "            # Feature 2: Rings\n",
        "            edge_feats.append(bond.IsInRing())\n",
        "            # Append node features to matrix (twice, per direction)\n",
        "            all_edge_feats += [edge_feats, edge_feats]\n",
        "\n",
        "        all_edge_feats = np.asarray(all_edge_feats)\n",
        "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_adjacency_info(self, mol):\n",
        "        \"\"\"\n",
        "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
        "        but we want to be sure that the order of the indices\n",
        "        matches the order of the edge features\n",
        "        \"\"\"\n",
        "        edge_indices = []\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            edge_indices += [[i, j], [j, i]]\n",
        "\n",
        "        edge_indices = torch.tensor(edge_indices)\n",
        "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
        "        return edge_indices\n",
        "\n",
        "    def _get_labels(self, label):\n",
        "        label = np.asarray([label])\n",
        "        return torch.tensor(label, dtype=torch.int64)\n",
        "\n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
        "            - Is not needed for PyG's InMemoryDataset\n",
        "        \"\"\"\n",
        "        if self.test:\n",
        "            data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_test_{idx}.pt'))\n",
        "        else:\n",
        "            data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_{idx}.pt'))\n",
        "        return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dataset featurizer\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import deepchem as dc\n",
        "from rdkit import Chem\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
        "\n",
        "class MoleculeDataset(Dataset):\n",
        "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
        "        \"\"\"\n",
        "        root = Where the dataset should be stored. This folder is split\n",
        "        into raw_dir (downloaded dataset) and processed_dir (processed data).\n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.filename = filename\n",
        "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
        "            (The download func. is not implemented here)\n",
        "        \"\"\"\n",
        "        return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "\n",
        "        if self.test:\n",
        "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
        "        else:\n",
        "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
        "\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "        featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
        "        for index, row in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "            # Featurize molecule\n",
        "            mol = Chem.MolFromSmiles(row[\"smiles\"])\n",
        "            f = featurizer._featurize(mol)\n",
        "            data = f.to_pyg_graph()\n",
        "            data.y = self._get_label(row[\"HIV_active\"])\n",
        "            data.smiles = row[\"smiles\"]\n",
        "            if self.test:\n",
        "                torch.save(data,\n",
        "                    os.path.join(self.processed_dir,\n",
        "                                 f'data_test_{index}.pt'))\n",
        "            else:\n",
        "                torch.save(data,\n",
        "                    os.path.join(self.processed_dir,\n",
        "                                 f'data_{index}.pt'))\n",
        "\n",
        "\n",
        "    def _get_label(self, label):\n",
        "        label = np.asarray([label])\n",
        "        return torch.tensor(label, dtype=torch.int64)\n",
        "\n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
        "            - Is not needed for PyG's InMemoryDataset\n",
        "        \"\"\"\n",
        "        if self.test:\n",
        "            data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_test_{idx}.pt'))\n",
        "        else:\n",
        "            data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_{idx}.pt'))\n",
        "        return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
        "from torch_geometric.nn import TransformerConv, TopKPooling\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, feature_size, model_params):\n",
        "        super(GNN, self).__init__()\n",
        "        embedding_size = model_params[\"model_embedding_size\"]\n",
        "        n_heads = model_params[\"model_attention_heads\"]\n",
        "        self.n_layers = model_params[\"model_layers\"]\n",
        "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
        "        top_k_ratio = model_params[\"model_top_k_ratio\"]\n",
        "        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
        "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
        "        edge_dim = model_params[\"model_edge_dim\"]\n",
        "\n",
        "        self.conv_layers = ModuleList([])\n",
        "        self.transf_layers = ModuleList([])\n",
        "        self.pooling_layers = ModuleList([])\n",
        "        self.bn_layers = ModuleList([])\n",
        "\n",
        "        # Transformation layer\n",
        "        self.conv1 = TransformerConv(feature_size,\n",
        "                                    embedding_size,\n",
        "                                    heads=n_heads,\n",
        "                                    dropout=dropout_rate,\n",
        "                                    edge_dim=edge_dim,\n",
        "                                    beta=True)\n",
        "\n",
        "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
        "        self.bn1 = BatchNorm1d(embedding_size)\n",
        "\n",
        "        # Other layers\n",
        "        for i in range(self.n_layers):\n",
        "            self.conv_layers.append(TransformerConv(embedding_size,\n",
        "                                                    embedding_size,\n",
        "                                                    heads=n_heads,\n",
        "                                                    dropout=dropout_rate,\n",
        "                                                    edge_dim=edge_dim,\n",
        "                                                    beta=True))\n",
        "\n",
        "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
        "            self.bn_layers.append(BatchNorm1d(embedding_size))\n",
        "            if i % self.top_k_every_n == 0:\n",
        "                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
        "\n",
        "\n",
        "        # Linear layers\n",
        "        self.linear1 = Linear(embedding_size*2, dense_neurons)\n",
        "        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))\n",
        "        self.linear3 = Linear(int(dense_neurons/2), 1)\n",
        "\n",
        "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
        "        # Initial transformation\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = torch.relu(self.transf1(x))\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        # Holds the intermediate graph representations\n",
        "        global_representation = []\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
        "            x = torch.relu(self.transf_layers[i](x))\n",
        "            x = self.bn_layers[i](x)\n",
        "            # Always aggregate last layer\n",
        "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
        "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
        "                    x, edge_index, edge_attr, batch_index\n",
        "                    )\n",
        "                # Add current representation\n",
        "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
        "\n",
        "        x = sum(global_representation)\n",
        "\n",
        "        # Output block\n",
        "        x = torch.relu(self.linear1(x))\n",
        "        x = F.dropout(x, p=0.8, training=self.training)\n",
        "        x = torch.relu(self.linear2(x))\n",
        "        x = F.dropout(x, p=0.8, training=self.training)\n",
        "        x = self.linear3(x)\n",
        "\n",
        "        return x"
      ]
    }
  ]
}